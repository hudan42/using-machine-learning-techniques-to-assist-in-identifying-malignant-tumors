---
title: "IDS_Final_Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```



```{r}
# Load all the libraries we need.
library(tidyverse)
library(stringr)
library(rpart)
library(partykit)
library(randomForest)
library(class)
```


```{r}
# Load the data set. Assign it to the variable 'fna'.
fna <- read_csv("FNA_cancer.csv")
glimpse(fna)
```

```{r}
# Make a copy of the original data set and delete the first and last column which are useless. Assign it with a new variable 'fna_new'.
fna_new <- data.frame(fna)
fna_new <- fna_new %>% select(-id, -X33)
glimpse(fna_new)
```


```{r}
# Replace the dot sign in column names with underscore so that all column names are in uniform form.
names(fna_new) <- str_replace_all(names(fna_new), '[.]', '_')

# Conver the response variable 'diagnosis' into factor.
fna_new$diagnosis <- as.factor(fna_new$diagnosis)

glimpse(fna_new)
```


### 2. Perform basic exploratory data analysis.

```{r}
# Create a vecor of 10 features of the cell nuclei.
features <- c('radius', 'texture', 'perimeter', 'area', 'smoothness', 'compactness', 'concavity', 'concave_points', 'symmetry', 'fractal_dimension')
```



```{r}
# Iterate over the 10 features of cell nuclei, and print the numeric summary of their accordingly mean, standard error of the mean, and the maximum.
for (i in 1:10) {
  for (j in seq_along(names(fna_new))) {
    if (str_detect(names(fna_new)[j], features[i])) {
      print(summary(fna_new[names(fna_new)[j]]))
    }
  }
}
```


```{r}
summary(fna_new)
```




### 3. Split the data into test and training data.
```{r}
# Set the seed to 1847
set.seed(1847)

# Get the total rows of the dataset. Assign the result to the variable 'n'.
n <- nrow(fna_new)

# Randomly generate the indexes for the test set. Use the indexes to select the 20% test set. Assign the test set to the variable 'test'.
test_idx <- sample.int(n, size = round(0.2 * n))
test <- fna_new[test_idx, ]

# Select the rest 80% training data and assign it to the variable 'train'.
train <- fna_new[-test_idx, ]

# Give a glimpse of the resulting training set.
glimpse(train)

# Give a glimpse of the resulting testing set.
glimpse(test)
```


### 4. Build a classification algorithm using decision trees. Prune your tree appropriately.
```{r}
# Create the regression formula, take 'diagnosis' as the response variable and all the rest 30 characteristics as the predictor variables. Assign the formula to the variable 'form'.
form <- as.formula(diagnosis ~ .)

# Create a tree using the formula just created. Assign the new tree to the variable 'diagnosis_tree'.
diagnosis_tree <- rpart(form, data = train)
plot(as.party(diagnosis_tree))

# Use 'diagnosis_tree' model to predict the test data and assign the predictions to the variable 'test_pred_tree'.
test_pred_tree <- predict(diagnosis_tree, newdata = test, type = 'class')

# Create the confusion matrix for the test data set. Assign the result to the variable 'confusion_tree'.
confusion_tree <- table(test$diagnosis, test_pred_tree)
confusion_tree
```

```{r}
printcp(diagnosis_tree)
```



### 5. Build a classification algorithm using random forests/bagging. Adjust the parameters of the forest appropriately.
```{r}
# Create a bagged(so mtry = 30) set of trees from the training data set. Assign the result to the variable 'diagnosis_bagging'.
diagnosis_bagging <- randomForest(form, data = train, mtry = 30, ntree = 500, na.action = na.roughfix)
diagnosis_bagging

# Use 'diagnosis_bagging' model to predict the test data and assign the predictions to the variable 'test_pred_bagging'.
test_pred_bagging <- predict(diagnosis_bagging, newdata = test, type = 'class')

# Create the confusion matrix for the test data set. Assign the result to the variable 'confusion_bagging'.
confusion_bagging <- table(test$diagnosis, test_pred_bagging)
confusion_bagging
```


```{r}
# Create a random forest from the training data set, set the mtry = 6. Assign the result to the variable 'diagnosis_forest'.
diagnosis_forest <- randomForest(form, data = train, mtry = 6, ntree = 500, na.action = na.roughfix)
diagnosis_forest

# Use 'diagnosis_forest' model to predict the test data and assign the predictions to the variable 'test_pred_forest'.
test_pred_forest <- predict(diagnosis_forest, newdata = test, type = 'class')

# Create the confusion matrix for the test data set. Assign the result to the variable 'confusion_forest
confusion_forest <- table(test$diagnosis, test_pred_forest)
confusion_forest
```


### 6. Build a classification algorithm using Kth Nearest Neighbors. Tune the value of K appropriately.
```{r}
# Rescale


# Conduct a KNN classification of the diagnosis variable, set the k parameter to 21. Assign the result to 'diagnosis_knn'.
diagnosis_knn <- knn(train = train[-1], test = test[-1], cl = train$diagnosis, k = 21)

# Calculate the confusion matrix for the test data. Assign the result to the variable 'confusion_knn'.
confusion_knn <- table(diagnosis_knn, test$diagnosis)
confusion_knn
```




